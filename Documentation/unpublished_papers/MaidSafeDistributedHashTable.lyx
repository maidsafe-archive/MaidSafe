#LyX 1.6.7 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass IEEEtran
\use_default_options false
\language british
\inputencoding default
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_title "MaidSafe Distributed Hash Table"
\pdf_author "David Irvine"
\pdf_subject "Distributed Hash Tables"
\pdf_keywords "security, freedom, privacy, DHT, encryption"
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_amsmath 0
\use_esint 0
\cite_engine basic
\use_bibtopic true
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Title
MaidSafe Distributed Hash Table
\end_layout

\begin_layout Author
David Irvine, email: david.irvine@maidsafe.net, LifeStuff: David
\end_layout

\begin_layout Right Address
maidsafe.net limited (registered in Scotland Sc 297540)
\end_layout

\begin_layout Date
September, 2010
\end_layout

\begin_layout Abstract
An effective distributed network requires an addressing mechanism and distributi
on of data that is designed to overcome churn (the unmanageable outage,
 node failure or unforeseen communication fault).
 There are several implementations of such a system, but this paper proposes
 a system that not only provides an efficient churn-resistant DHT, but also
 has fast awareness of infrastructure changes.
 This allows the implementation of a locking system, thereby enabling amendment
 of data from multiple sources.
\end_layout

\begin_layout Keywords
security, freedom, privacy, DHT, encryption
\end_layout

\begin_layout MarkBoth
maidsafe.net limited company confidential Version 0.1
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}{
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
PARstart{D}{istributed}
\end_layout

\end_inset

 hash tables are a method of storing data in a key / value system in a distribut
ion that should be set to allow for multiple node failures.
 This particular DHT implementation is based upon Kademlia as described
 in 
\emph on
Kademlia: A Peer-to-peer Information System Based on the XOR Metric
\emph default

\begin_inset CommandInset citation
LatexCommand cite
key "5"

\end_inset

.
 
\end_layout

\begin_layout Standard
Data validity is achieved in Kadmelia by selecting a value for the replication
 factor (
\begin_inset Formula $\kappa$
\end_inset

) that is the number defined as the optimum node count in a network that
 will not fail between refresh times 
\begin_inset Formula $\mathsf{f(t)}$
\end_inset

.
 This 
\begin_inset Formula $\mathsf{f(t)}$
\end_inset

 is generally set to a system wide constant and obeyed by all nodes.
 In an improved version of the refresh as identified in 
\emph on
Improving the Performance and Robustness of Kademlia-based Overlay Networks
 
\begin_inset CommandInset citation
LatexCommand cite
key "6"

\end_inset

 this 
\emph default

\begin_inset Formula $\mathsf{f(t)}$
\end_inset

is not fixed but distributed over a period where nodes should refresh in
 a more random fashion.
 This reduces refresh traffic on the network and allows all the 
\begin_inset Formula $\kappa$
\end_inset

 nodes to reset their refresh timers.
 This paper presents a system that removes this refresh timer altogether
 in favour of a solution that is closer to real time.
 
\end_layout

\begin_layout Standard
In addition the paper 
\emph on
Improving the Performance and Robustness of Kademlia-based Overlay Networks
 
\begin_inset CommandInset citation
LatexCommand cite
key "6"

\end_inset

 
\emph default
also promotes a system of down list, whereby a node that is found to be
 down is reported by the node searching for it back to the node that provided
 this dead nodes details in a search iteration.
 This is a significant improvement in the Kadmelia network and with a 
\begin_inset Formula $\kappa$
\end_inset

 of 20 is reportedly takes the current accuracy measurement of a 
\begin_inset Formula $\kappa$
\end_inset

 bucket from 
\begin_inset Formula $\mathsf{13/20}$
\end_inset

 to 
\begin_inset Formula $\mathsf{19.8/20}$
\end_inset

 good nodes.
 This is a dramatic improvement and will again save on network traffic and
 time-outs wasted on dead nodes.
 The system presented here will improve on this performance significantly.
 
\end_layout

\begin_layout Section
Kademlia observations
\begin_inset CommandInset label
LatexCommand label
name "sec:Kademlia-observations"

\end_inset


\end_layout

\begin_layout Standard
Some issues with Kademlia and DHTs in general is the ability to amend (or
 delete) values after publishing.
 This is due to the inherent distributed nature of the values (as the name
 suggests).
 As values are distributed in a pseudo random manner (mathematical predictabilit
y becomes an issue due to the large amount of variables (routes, nodes,
 node names, locations etc.) and random
\begin_inset Foot
status open

\begin_layout Note
Random here is used to indicate not computationally recognisable with today's
 resources.
\end_layout

\end_inset

 human input).
 
\end_layout

\begin_layout Note
Searches on Kademlia networks are very fast and iterative (
\emph on
not recursive
\emph default
).
 This means that each node will ask some nodes a question, get answers (hopefull
y) and from the answers construct a new node list to ask.
 If this were recursive, then a failed node would halt the process; as this
 is iterative then failed nodes simply time-out whilst the search continues
 (this is the 
\begin_inset Formula $\beta$
\end_inset


\begin_inset Formula $\mbox{}$
\end_inset

 (required replies to continue) requirement, from the 
\begin_inset Formula $\alpha$
\end_inset

 (loosely parallel level) searches).
 As Kademlia uses a binary tree and XOR searching the search time per iteration
 is 
\begin_inset Formula $\mathcal{O}\ln n$
\end_inset

 (where 
\begin_inset Formula $\mathcal{O}$
\end_inset

 is network latency and a factor of XOR distance between node IDs (holes
 in address space) and n is number of nodes, not number of possible nodes).
 This figure can be improved upon by the additions shown so far.
 Further examination of the 
\begin_inset Formula $\mathcal{O}$
\end_inset

 constant may lead to further improvements in search completion times by
 not only using decreasing distance but also decreasing distance with path
 protection (multiple routes protected) by examination of XOR distance between
 parts of the network, particularly where there is binary imbalance in early
 days.
 
\end_layout

\begin_layout Subsection
Value Handling
\begin_inset CommandInset label
LatexCommand label
name "sub:Value-Handling"

\end_inset


\end_layout

\begin_layout Standard
In Kademlia there are several methods of ensuring values are consistent
 and protected at the same time.
 The initial value to be considered is K and this should be chosen to be
 the number of random nodes that can be allowed to go offline in a Refresh
 (Refresh) time.
 There is also a republish time (Repub) which is the initial store of the
 value and sets a time to live (TTL) value on the data.
 It should be noted in the maidsafe_dht this TTL may be set at (-1), representin
g do not time-out.
 In cases where a TTL is set, then the publisher must store the data again
 (effectively resetting the TTL) should it wish to maintain the data for
 an extended period.
 
\end_layout

\begin_layout Subsubsection
Caching
\begin_inset CommandInset label
LatexCommand label
name "sub:Caching"

\end_inset


\end_layout

\begin_layout Standard
In Kademlia, values are cached distant from their natural location of the
 
\begin_inset Formula $\kappa$
\end_inset

 closest nodes.
 The values are cached using a simple mechanism, whereby the last node that
 did not have the value, is given if for future searches.
 This increases efficiency of search and reduced the iteration count.
 There is currently no mechanism in Kademlia to use these cached values
 to improve data consistency.
 See section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Caching-new"

\end_inset

 for an improvement based upon this omission.
 
\end_layout

\begin_layout Standard
The TTL is used in this instance to calculate how long a value can live
 and the further away from the 
\begin_inset Formula $\kappa$
\end_inset

 closest determines the TTL value that each value has.
 This value is chosen as the reciprocal of the distance from 
\begin_inset Formula $\kappa$
\end_inset

 of the value (this distance is the XOR (
\begin_inset Formula $\oplus$
\end_inset

) distance).
 This distance figure may be further analysed to proved a more efficient
 mechanism such as the 
\begin_inset Formula $\mathsf{1/(\oplus\, distance/current\,\, height\, of\, tree)}$
\end_inset

 to be more effective and accurate.
 
\end_layout

\begin_layout Standard
This can present issues when the refresh time (usually 60 mins but configurable)
 is due.
 In this case the node must check it is in the 
\begin_inset Formula $\kappa$
\end_inset

 closest and if so refresh (i.e.
 send a store_value) the 
\begin_inset Formula $\kappa$
\end_inset

 closest nodes.
 
\begin_inset Formula $\beta$
\end_inset

 refresh, as described in 
\begin_inset CommandInset citation
LatexCommand cite
key "6"

\end_inset

 is used to vary in an evenly distributed way the 60 minute intervals to
 reduce potential for race conditions in republishing values.
 
\end_layout

\begin_layout Subsubsection
Time To Live Values
\end_layout

\begin_layout Standard
The TTL can be different for any different type of file, from seconds to
 a figure indicating do not delete ever (i.e.
 -1).
 For fast changing data the TTL should be small, and for unchanging data
 (like digital keys) the TTL should be very large.
 This value is only reset by the storing node unless another algorithm for
 that value type is known by the Kademlia node.
 Extending kademlia nodes to validate rules based on data types is explain
 in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Extending-validation-checks"

\end_inset


\end_layout

\begin_layout Subsection
Routing table architecture
\end_layout

\begin_layout Standard
An empirical and difficult to understand part of Kademlia is the routing
 table.
 This routing table in a very clever, yet misunderstood part of XOR based
 routing.
 It all starts with a single 
\begin_inset Formula $\kappa$
\end_inset

 bucket which 
\emph on
does not
\emph default
 contain the nodes own address.
 As the network starts up and nodes are added to this bucket it 
\emph on
splits
\emph default
.
 As more nodes are added the 1
\begin_inset Formula $\mathsf{^{\text{st}}}$
\end_inset

 bucket continues to split up to the point where there are 
\begin_inset Formula $\mathsf{n-1}$
\end_inset

 buckets.
 Nodes will continue to be added, which if no node vanished would mean the
 buckets would fill quickly to a maximum node count.
 As each bucket is created it covers an area of the network which is 
\begin_inset Formula $\mathsf{2^{n}}$
\end_inset

 in size.
 In this case n represents the bucket value starting from 
\begin_inset Formula $\mathsf{0}$
\end_inset

 all the way to 
\begin_inset Formula $\mathsf{n-1}$
\end_inset

 
\begin_inset Formula $\therefore$
\end_inset

the last bucket is 
\begin_inset Formula $\mathsf{2^{511}}$
\end_inset

 in this case is a 512 bit address size.
 In many cases it is simpler to think of the buckets address as the number
 of most significant bits in common with bucket n-1 having 1 bit in common
 and bucket 0 (the bucket the node should be in) as the bucket with n-1
 bits in common (i.e.
 leaving space of just 2 entries, a 0 and a 1).
 This number represents the number of nodes covered by this bucket, another
 way to think of this is that the bucket is responsible for routing in that
 area of the network.
\end_layout

\begin_layout Standard
It then becomes obvious that the last bucket covers half of the network
 address space 
\begin_inset Formula $\therefore$
\end_inset

 50% of all nodes will exist in a bucket containing 
\begin_inset Formula $\kappa$
\end_inset

 nodes.
 In the case under discussion we assumed a 
\begin_inset Formula $\kappa=4$
\end_inset

.
 4 Nodes then are all that is locally known about for information for the
 other half of the network from the address of the routing tables owner.
 
\end_layout

\begin_layout Standard
This is vital to understand that as the average distance between all the
 nodes in the last bucket is 
\begin_inset Formula $\mathsf{2^{n}/(2*\kappa)}$
\end_inset

 which is a significant distance.
 More importantly though the 1
\begin_inset Formula $\mathsf{^{st}}$
\end_inset

 bucket will contain nodes extremely close and in fact in a full network
 the first bucket would contain a single node in the last leaf of the binary
 tree shared by the nodes own address.
 
\end_layout

\begin_layout Standard
In essence the distribution of node distance known by each bucket increases
 logarithmically and therefore the knowledge of each segment represented
 by a bucket decreases logarithmically.
 This presents a difficult to comprehend system that is generally missed
 by a casual reader of a binary tree based XOR routing algorithm.
 
\end_layout

\begin_layout Section
Managed connections
\end_layout

\begin_layout Standard
Unlike other algorithms such as chord where each node maintains 
\begin_inset Formula $\mathsf{num\, keys/num\, nodes}$
\end_inset

 in Kademlia based networks each node maintains the keys that are between
 his ID and the ID of the 
\begin_inset Formula $\kappa$
\end_inset

 closest nodes.
 This combined with the fact that it is the nodes closest to any node that
 are more significant in terms of knowledge of the network.
 This basically states the closer a node is to you then the more you should
 know about it, for the network to operate correctly this is fundamental.
\end_layout

\begin_layout Standard
To achieve this Kademlia uses a notion of 
\begin_inset Formula $\kappa$
\end_inset

 buckets as described in 
\emph on
Kademlia: A Peer-to-peer Information System Based on the XOR Metric
\emph default

\begin_inset CommandInset citation
LatexCommand cite
key "5"

\end_inset

.
 The size of the routing table when expressed as 
\begin_inset Formula $\kappa$
\end_inset

 buckets is 
\begin_inset Formula $\mathsf{n-1}$
\end_inset

 where n is the size of the network address in bits.
 For a SHA1 based addressing scheme this is 159 buckets.
 Taking a traditional set-up for 
\begin_inset Formula $\kappa$
\end_inset

 of 20 this means the number of nodes in a routing table is a maximum value
 of 
\begin_inset Formula $\mathsf{159*20=3180}$
\end_inset

.
 The maidsafe_dht default address space size is 512 (SHA512) which would
 equate to a routing table node count of 
\begin_inset Formula $\mathsf{511*20=10,220}$
\end_inset

, reducing 
\begin_inset Formula $\kappa$
\end_inset

 to perhaps 4 would dramatically reduce the routing table size to a more
 manageable 
\begin_inset Formula $\mathsf{511*4=2044}$
\end_inset

.
 A 
\begin_inset Formula $\kappa$
\end_inset

 value of 4 though is perhaps dangerous unless the refresh value was very
 small indeed, creating lots of traffic in the balance between integrity
 and network congestion.
\end_layout

\begin_layout Standard
The traffic due to down-list and refresh is reasonably high and exists in
 an attempt to ensure routing tables are maintained with live nodes as well
 as maintaining data on the network in a reliable fashion.
\end_layout

\begin_layout Subsection
DHT transport 
\end_layout

\begin_layout Standard
In this DHT implementation, unlike pure Kademlia, we use a reliable transport
 mechanism, although like Kademlia, the underlying transport is User Datagram
 Protocol (UDP).
 In this case a version of reliable overlay was chosen and is currently
 UDT
\begin_inset Foot
status open

\begin_layout Plain Layout
A UDP transport also allows traversal of Network Address Translation (NAT)
 devices allowing nodes to traverse routers.
 This explanation is extended in the paper 
\emph on
maidsafe_dht NAT traversal
\emph default

\begin_inset CommandInset citation
LatexCommand cite
key "3"

\end_inset

.
\end_layout

\end_inset

, although this is open to change.
 
\end_layout

\begin_layout Standard
Such transports, like Transport Control Protocol (TCP), sequence data being
 transferred to allow the receiver to notify the sender on message segment
 failure, which can be re-transmitted.
 UDT uses a system of transmitting the acknowledgements of sequences received
 every 
\begin_inset Formula $\delta$
\end_inset

 times and increasing the value of 
\begin_inset Formula $\delta$
\end_inset

 on success.
 This allows a faster throughput that TCP, which acknowledges every packet
 sent.
\end_layout

\begin_layout Standard
UDT allows the network to create connections between nodes and keep these
 alive by sending very small single bit transmissions every 
\begin_inset Formula $\gamma$
\end_inset

 seconds.
 These connections (sockets) if made on the same sending port can allow
 a demultiplexer to handle many connections with little effort, reducing
 system overhead.
 
\end_layout

\begin_layout Standard
Using this systetm a managed connection, or a connection that is not closed
 transmits a very small packet every 
\begin_inset Formula $\gamma$
\end_inset

 seconds with a count of failures 
\begin_inset Formula $\delta$
\end_inset

.
 The minimum time to find a node dead is approximately 30milliseconds for
 nodes that gracefully leave the network or 
\begin_inset Formula $\gamma$
\end_inset

*
\begin_inset Formula $\delta$
\end_inset

 in the worst case where a node crashes or becomes disconnected without
 notice.
\end_layout

\begin_layout Subsection
Overhead per connection
\end_layout

\begin_layout Standard
In tests the memory overhead per connection is approximately 500Kb.
 This can be further reduced by removing some unused attributes of a socket
 structure.
 The memory overhead is likely to be reduced to between 80 and 150Kb.
 This paper will assume a connection memory overhead of 150Kb.
 It is possible that an efficient serialisation mechanism could further
 reduce this with in memory structures and on disk structures to complete
 all the socket requirements, allowing either complete socket structures
 or partial structures to exist on disk, making more efficient use of Random
 Access Memory (RAM).
 
\end_layout

\begin_layout Standard
The bandwidth costs per managed connection is less than 0.5 bytes per second,
 given a value of 
\begin_inset Formula $\gamma=2$
\end_inset

 .
\end_layout

\begin_layout Subsection
Additional logic required for 1
\begin_inset Formula $\mathsf{^{st}\kappa Bucket}$
\end_inset

 
\end_layout

\begin_layout Standard
In the first bucket, where the values are held, it is imperative that values
 are shared between the nodes.
 A value must be shared by all the 
\begin_inset Formula $\kappa$
\end_inset

 nodes.
 Ordinarily a refresh carries out this process, but with managed connections,
 refresh is not called any more.
 Therefore some logic has to be put in place to ensure values are indeed
 distributed.
 
\end_layout

\begin_layout Standard
An additional RPC is required:
\end_layout

\begin_layout Standard
GIVE_VALUE[values] -> this RPC is executed when a node joins the 
\begin_inset Formula $\kappa$
\end_inset

 closest to any node.
 The function is to pass all values between the nodes address and the address
 of the connecting node.
\end_layout

\begin_layout Standard
This RPC should now be sent on joining a 
\begin_inset Formula $\kappa$
\end_inset

 group, or on finding a node is now part of your 
\begin_inset Formula $\kappa$
\end_inset

 .
 This RPC should also be sent to each node in the 
\begin_inset Formula $\kappa$
\end_inset

 closest to any value held by a node in the event of 
\emph on
any
\emph default
 amendments to 
\emph on
any 
\emph default
values.
\end_layout

\begin_layout Standard
The refresh logic of Kademlia is now no longer required as long as a managed
 connection is maintained for the 
\begin_inset Formula $\kappa$
\end_inset

 closest nodes at least.
\end_layout

\begin_layout Subsection
Using Managed connections for all routing table entries (requires simulation
 - VERY IMPORTANT)
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $\kappa$
\end_inset

 could be reduced to a suitably small number (say 4 or even 2, see below)
 then the number of connections required may be small enough to hold many
 hundreds connections, particularly through a single port and multiplexer
 point.
 In this case the complete network would be relatively current and there
 would be no requirement for down-list logic (another reduction in code).
 
\end_layout

\begin_layout Subsubsection
Incoming connections
\end_layout

\begin_layout Standard
In the case where all routing table entries are in fact managed connections,
 it is not only the routing table entries that require to be managed by
 the node.
 Other nodes who add the current node to their routing table will create
 connections back to this node.
 This increases the number of structs to be maintained and could grow to
 a very significant number.
 
\end_layout

\begin_layout Standard
In such network the nodes in one routing table should not be the same nodes
 in another routing table, this is also a logarithmically possible situation
 and the higher buckets should increasingly follow this rule, with the closer
 buckets being likely to have two way nodes that exists in each, particularly
 the 
\begin_inset Formula $\kappa$
\end_inset

 bucket.
 The bucket n-1 for instance should certainly not share contacts between
 nodes.
\end_layout

\begin_layout Standard
To ensure such a system may work effectively the number of connections required
 is in fact 
\begin_inset Formula $\mathsf{2*\kappa*n}$
\end_inset

.
 This allows each bucket to maintain its 
\begin_inset Formula $\kappa$
\end_inset

 outgoing connections and accept 
\begin_inset Formula $\kappa$
\end_inset

 incoming connections.
 This may slow down the population of all 
\begin_inset Formula $\kappa$
\end_inset

 buckets per node as many may refuse the incoming connections as its 
\begin_inset Formula $\kappa$
\end_inset

 bucket is full.
 
\end_layout

\begin_layout Subsubsection
Replica value count
\end_layout

\begin_layout Standard
In standard Kademlia the replica number is 
\begin_inset Formula $\kappa$
\end_inset

 which suffices and perhaps even improves algorithmic efficiency (through
 simplicity).
 There is no reason for this to remain the case and with managed connections
 and much lower values of 
\begin_inset Formula $\kappa$
\end_inset

 there is no reason whatsoever for the value replicant count to be 
\begin_inset Formula $\kappa*2$
\end_inset

 (or any arbitrary number for that matter).
 
\end_layout

\begin_layout Standard
In cases where 
\begin_inset Formula $\kappa$
\end_inset

 is a low value (such as 2) then using a replicant count of 
\begin_inset Formula $\kappa*2$
\end_inset

 allows a further increase in data retention, this should be a consideration
 when reducing the size of the routing table for obvious reasons.
 
\end_layout

\begin_layout Standard
This presents no issues for the DHT and does not impact adversely on any
 algorithmic complexity.
 
\end_layout

\begin_layout Subsection
Recursive lookups
\end_layout

\begin_layout Standard
It is very important in distributed computing not to hold state on remote
 actions.
 This is because remote actions are just that, remote and therefore out
 of your control.
 Kademlia handles this well with iterative searches carried out in a loosely
 parallel fashion as described in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Kademlia-observations"

\end_inset

.
 
\end_layout

\begin_layout Standard
With managed connections, however, there is a different situation as we
 are working with a very current network of nodes who are all in communication.
 In such a case a recursive lookup may prove significantly faster and also
 with much less network traffic.
 
\end_layout

\begin_layout Standard
This recursive lookup can now be a single message to the closest node in
 the routing table, who recursively passes on to their closest node and
 so on.
 On any failure the recursion would continue from the previous node to the
 failure, who has an open RPC that will fail to the failed node and can
 easily select the next closest node.
 
\end_layout

\begin_layout Standard
On finding a node or value the requester is passed the contact tuple of
 the node in question from the last node in the chain (not the actual node
 who has the answer) and then continues with normal kademlia logic, which
 may involve getting the 
\begin_inset Formula $\kappa$
\end_inset

 closest nodes in a find node situation or simply getting a value in the
 get value situation.
 Caching and last node requests in addition to caching (in future) can then
 also cache the value in a find value request and do so without being requested.
 
\end_layout

\begin_layout Section
Additional improvements
\end_layout

\begin_layout Subsection
Resilient caching
\begin_inset CommandInset label
LatexCommand label
name "sub:Caching-new"

\end_inset


\end_layout

\begin_layout Standard
As explained in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Caching"

\end_inset

, caching can be used to improve data reliability at the DHT level with
 an improved caching algorithm.
 As described cache data will expire faster than actual data, this is by
 design to remove the possibility of stale data.
 This is a wise stance to take, as stale data may prove to be extremely
 cumbersome and pollute the data store.
 
\end_layout

\begin_layout Standard
As described in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Value-Handling"

\end_inset

, only the publisher should republish information.
 This makes perfect sense and the responsibility to do so should lie with
 the publisher.
 This does not, however, mean the network should not attempt to maintain
 the data up to the TTL expiration time
\begin_inset Foot
status open

\begin_layout Plain Layout
it should be noted here that all time is relative to an event and never
 time from a date that is used.
 This allows the network to refrain from time synchronisation services in
 order to calculate events.
\end_layout

\end_inset

 has elapsed.
 
\end_layout

\begin_layout Standard
The additional rules in this case, are relatively simple, a node easily
 can detect it is holding cache data, it may even be stored in a different
 location from current data.
 When the TTL is close to expiring the node should check the 
\begin_inset Formula $\kappa$
\end_inset

 closest nodes supposedly holding the data still have a copy and if not
 republish it to them.
 If a node that should have the data receives such a store command from
 a cache node it should calculate the distance the node is from it and multiply
 the reciprocal time used to calculate caching in the first instance, thereby
 increasing the TTL from nearly zero back to the value closer to the actual
 TTL the value should be set at.
 This process should take place a reasonable time before delete such as
 30 mins.
 This can be improved on by using the original TTL and dividing by distance
 and use half the remaining TTL as the trigger in the remote node.
 Each time half the TTL remaining comes around again the remote node can
 trigger a consistency check and store the data again if required by the
 network.
 A suitable minimum time can be set by the system (say 180 secs) where this
 consistency check stops (this is the kConsistencyStop setting).
 In nodes with a -1 TTL (infinity) this consistency check is settable by
 the designer (kConsistencyCheck).
\end_layout

\begin_layout Standard
If a value is deleted the closest nodes with the value (k closest) should
 be updated with a -1 value and this should not be cached, this prevents
 cached copies actually republishing values that are due to be removed anyway
 (i.e.
 ignoring or overriding the delete instruction).
\end_layout

\begin_layout Subsection
Extending validation checks based on data types
\begin_inset CommandInset label
LatexCommand label
name "sub:Extending-validation-checks"

\end_inset


\end_layout

\begin_layout Standard
In standard Kademlia all data is treated equally, in that all key value
 pairs are just that.
 maidsafe_dht allows signed values and uses an extension of this system
 to cope with different rules for a value.
 These rules allow manipulation of data based on pre programmed actions.
 This allows for a very flexible and very secure network to be created.
 
\end_layout

\begin_layout Standard
Some inbuilt rules are:
\end_layout

\begin_layout Enumerate
Only the signatory of a value can delete or amend the value with a remaining
 TTL
\end_layout

\begin_layout Enumerate
If signed data exists all values must be signed (in this case a node is
 configured as secure and will only talk with other secure nodes and store
 secure data)
\end_layout

\begin_layout Enumerate
Multiple values may exist for any key, and all or none may be independently
 signed.
 
\end_layout

\begin_layout Standard
In maidsafe_dht there is an interface which allows the user to extend the
 functionality of store/delete/amend data.
 This allows applications using such a system to implement different data
 (or more correctly value) types and associate functions with those data
 types.
 In it's simplest for these rules are based on the identified actions 
\emph on
store, delete and amend
\emph default
.
 There are infinitely more possibilities to this process with the inclusion
 of an unknown RPC message, given and unknown (or not recognised in our
 rule set) RPC the upper layer applications can act on these RPC's, allowing
 multiple action types to be executed based on the RPC sent, in this case
 the DHT layer will signal upper layers with a numbered signal message that
 the upper layer can parse and associate the correct logic, which may include
 amend a value including append data to the value, in such cases the DHT
 layer will in turn be signalled to carry out a refresh (or more accurately
 resynchronise the value in the network, which in this case is permeate
 the new value (which requires signatures in a signed system)).
 
\end_layout

\begin_layout Subsection
Delete or modify values
\end_layout

\begin_layout Subsubsection
Description
\end_layout

\begin_layout Standard
As previously stated, modifying a value in a distributed hash table is notorious
ly difficult.
 This is endemic in the very nature of the pseudo random distribution of
 data in such a network (the DHT strength is one of the largest weaknesses
 here).
 If a single value is altered via any method, the value itself may exist
 in many places and it's finding these places that's the problem.
 We have already seen the distribution as random, therefore this implies
 you would be required to search every node in the network (not only closest)
 for copies and make sure they are also altered.
 To make this even more difficult, another node may also be altering the
 value at the same time, thereby causing chaos in the synchronising of data
 on the network, eventually leading to total collapse.
\end_layout

\begin_layout Standard
This would imply that DHTs are only good read only, however, in the case
 of maidsafe_dht, this negative attribute is turned into a positive and
 essential aspect.
 As noted trying to alter the content of a packet of data that hashes to
 the key is an illegal instruction in some situations (LifeStuff and msSAN
 use this extensively).
 
\end_layout

\begin_layout Subsubsection
Locks
\end_layout

\begin_layout Standard
To achieve reliability of data where multiple copies may exist and be altered
 from multiple locations is a problem that requires addressing, before changing
 data.
 Using the above scenario a node intending to alter a piece of data tries
 to get all the k-closest nodes via an search.
 On success each node is sent a lock request which it answers with (Acknowledge)
 ACK or (Negative Acknowledge) NACK.
 Each node can pass this request to its known k-closest nodes.
 On receipt of 
\begin_inset Formula $\kappa$
\end_inset

 ACKs, the node then alters the value.
 On receiving an altered value the holding nodes release the lock.
 Failure to receive a value update in 
\begin_inset Formula $\eta$
\end_inset

 seconds (settable) seconds should auto release the lock.
 
\end_layout

\begin_layout Standard
Two locks in collision (which can still happen) are both sent a NACK and
 back off for a random period.
 This may be a defined algorithm based on network address at a future date.
 With managed connections this is less likely as the response will be very
 quick.
\end_layout

\begin_layout Standard
In a secured versions of maidsafe_dht this process has the further check
 of signature validation which should prevent all collisions.
\end_layout

\begin_layout Section
Conclusions
\end_layout

\begin_layout Standard
The maidsafe_dht presented here is very loosely based on Kademlia.
 The addition of managed connections is very interesting and makes great
 use of a connections based protocol where it would appear more obvious
 to use a connectionless protocol for speed and network efficiency.
 The move from multiple iterative searches to single recursive searches
 should prove to be vastly more efficient and significantly faster.
 The disconnection of 
\begin_inset Formula $\kappa$
\end_inset

 bucket size from number of replicants values is also significant in allowing
 a smaller number of routing table entries, but improving data retention
 and validity.
 
\end_layout

\begin_layout Standard
This represents a use of a DHT system that is exceptionally powerful in
 distributing network knowledge (Kademlia) and extending this with a system
 of improvements that transform the DHT into a network that can cope with
 increasingly quickly altering data.
 This should represent an improvement in distributed networking and distributed
 processing.
 
\end_layout

\begin_layout Section
Future work
\end_layout

\begin_layout Subsection
Consider equal distribution of nodes per bucket
\end_layout

\begin_layout Standard
To improve performance of searches the distribution of nodes per bucket
 is important, particularity as the number of buckets increases.
 This will also ensure a more efficient calculation of tree height or number
 of nodes currently on the network based on distance between nodes in a
 routing table.
 Currently this is most effective in the n=0 bucket, in fact this is due
 to the fact that bucket should be most closely true in a randomly distributed
 network, it is also the highest error margin due to the lack of proper
 scale of measure.
 
\end_layout

\begin_layout Subsection
Consider pre populating buckets
\end_layout

\begin_layout Standard
An algorithm to pre populate buckets using a distance request may assist
 in mapping the network out quickly.
 This can be implemented using a system of asking for a node in bucket n
 asking for the nodes n-1 bucket of the same number.
 This can be easily expanded into a very efficient algorithm.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "1"
key "1"

\end_inset

As described by Van Jacobson in this link below, August 30, 2006 http://video.Goo
gle.com/videoplay?docid=-6972678839686672840
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "2"
key "2"

\end_inset

Stoica, Robert Morris, David Karger, M.
 Frans Kaashoek, and Hari Balakrishnan,Chord: A Scalable Peer-to-peer Lookup
 Service for Internet Applications
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "3"
key "3"

\end_inset

David Irvine, DHT-based NAT Traversal, david.irvine@maidsafe.net
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "4"
key "4"

\end_inset

David Irvine, maidsafe: A new networking paradigm, david.irvine@maidsafe.net
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "5"
key "5"

\end_inset

PETAR MAYMOUNKOV AND DAVID MAZI`RESE Kademlia: A Peer-to-peer Information
 System Based on the XOR Metric {petar,dm}@cs.nyu.edu http://Kademlia.scs.cs.nyu.edu
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "6"
key "6"

\end_inset

ANDREAS BINZENH ̈ FER AND HOLGER SCHNABEL.
 Improving the Performance and Robustness of Kademlia-based Overlay Networks
 o University of W ̈ rzburg, Institute of Computer Science u Chair of Distribute
d Systems, W ̈ rzburg, Germany u Email: binzenhoefer@informatik.uni-wuerzburg.de
 
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status collapsed

\begin_layout Plain Layout
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Change this paragraphs style to 'Standard' to enable
\end_layout

\begin_layout Plain Layout
BibTeX bibliography generation.
\end_layout

\begin_layout Plain Layout
Remember though that your final submission is supposed to have
\end_layout

\begin_layout Plain Layout
all the bibliography entries embedded in the latex file.
 This means
\end_layout

\begin_layout Plain Layout
you eventually have to copy the .bbl file into the latex file and
\end_layout

\begin_layout Plain Layout
remove the bibtex lines.
\end_layout

\end_inset


\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "your_biblio_file"
options "IEEEbib"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout BiographyNoPhoto
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

David Irvine
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 is a Scottish Engineer and innovator who has spent the last 12 years researchin
g ways to make computers function in a more efficient manner.
\end_layout

\begin_layout BiographyNoPhoto
He is an Inventor listed on more than 20 patent submissions and was Designer
 / Project Manager of one of the World's largest private networks (Saudi
 Aramco, over $300M).
 He is an experienced Project Manager and has been involved in start up
 businesses since 1995 and has provided business consultancy to corporates
 and SMEs in many sectors.
\end_layout

\begin_layout BiographyNoPhoto
He has presented technology at Google (Seattle), British Computer Society
 (Christmas Lecture) and many others.
\end_layout

\begin_layout BiographyNoPhoto
He has spent many years as a lifeboat Helmsman and is a keen sailor when
 time permits.
\end_layout

\end_body
\end_document
